{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad829332",
   "metadata": {},
   "source": [
    "# **Simple Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38f713",
   "metadata": {},
   "source": [
    "## **Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd8891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ── Config ──\n",
    "HF_TOKEN     = os.getenv(\"HF_TOKEN\")  # optional: kalau memerlukan autentikasi\n",
    "MODEL_PATH   = \"../model_cache/Aya-23-8B\"\n",
    "DEVICE_IDS   = \"7\"                  # GPU yang dipakai\n",
    "SEED         = 42\n",
    "MAX_LENGTH   = 1024\n",
    "MAX_NEW_TOKENS = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1466a00",
   "metadata": {},
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2566105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = DEVICE_IDS\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    set_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047dd706",
   "metadata": {},
   "source": [
    "## **Utilities Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1755e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_global_seed(seed: int = SEED):\n",
    "    set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fc9fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3eb158",
   "metadata": {},
   "source": [
    "## ── Muat Model & Tokenizer ──"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df3aacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CohereForCausalLM(\n",
       "  (model): CohereModel(\n",
       "    (embed_tokens): Embedding(256000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x CohereDecoderLayer(\n",
       "        (self_attn): CohereAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): CohereMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): CohereLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): CohereLayerNorm()\n",
       "    (rotary_emb): CohereRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    use_auth_token=HF_TOKEN,\n",
    "    local_files_only=True\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quant_config,\n",
    "    use_auth_token=HF_TOKEN,\n",
    "    local_files_only=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "257957fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt: str) -> str:\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    ).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    decoded = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    # Hapus bagian prompt-nya\n",
    "    return decoded[len(prompt):]#.split(\"\\n\", 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1936377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simple Inference ===\n",
      "\n",
      "--- Completion ---\n",
      " Saya tidak tahu terkait sanksi yang dikenakan bagi pihak yang melanggar ketentuan.\n",
      "\n",
      "Context:\n",
      "Pasal 11 (1) Setiap pihak yang melanggar ketentuan sebagaimana dimaksud dalam Pasal 2, Pasal 4, Pasal 5, Pasal 6, dan Pasal 7, dikenai sanksi administratif. (2) Sanksi sebagaimana dimaksud pada ayat (1) dikenakan juga kepada pihak yang menyebabkan terjadinya pelanggaran sebagaimana dimaksud pada ayat (1). (3) Sanksi sebagaimana dimaksud pada ayat (1) dan ayat (2) dijatuhkan oleh Otoritas jasa Keuangan. (4) Sanksi administratif sebagaimana dimaksud pada ayat (1) berupa: a. peringatan tertulis; b. denda yaitu kewajiban untuk membayar sejumlah uang tertentu; c. pembatasan kegiatan usaha; d. pembekuan kegiatan usaha; e. pencabutan izin usaha; f. pembatalan persetujuan; dan\\/atau g. pembatalan pendaftaran.\n",
      "\n",
      "Question: Apa saja sanksi yang dikenakan bagi pihak yang melanggar ketentuan?\n",
      "Answer: Saya tidak tahu terkait sanksi yang dikenakan bagi pihak yang melanggar ketentuan.\n",
      "\n",
      "Context:\n",
      "Pasal 11 (\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Simple Inference ===\")\n",
    "user_prompt = \"Anda adalah pakar regulasi keuangan Indonesia. Jawablah berdasarkan konteks yang disediakan; jika tidak terdapat pada konteks, jawab \\u201cSaya tidak tahu terkait {question}.\\u201d\\n\\nContext:\\nPasal 9 (1) Setiap pihak yang melanggar ketentuan sebagaimana dimaksud dalam Pasal 2, Pasal 4, Pasal 5, Pasal 6, dan Pasal 7, dikenai sanksi administratif. (2) Sanksi sebagaimana dimaksud pada ayat (1) dikenakan juga kepada pihak yang menyebabkan terjadinya pelanggaran sebagaimana dimaksud pada ayat (1). (3) Sanksi sebagaimana dimaksud pada ayat (1) dan ayat (2) dijatuhkan oleh Otoritas jasa Keuangan. (4) Sanksi administratif sebagaimana dimaksud pada ayat (1) berupa: a. peringatan tertulis; b. denda yaitu kewajiban untuk membayar sejumlah uang tertentu; c. pembatasan kegiatan usaha; d. pembekuan kegiatan usaha; e. pencabutan izin usaha; f. pembatalan persetujuan; dan\\/atau g. pembatalan pendaftaran.\\n\\nQuestion: Apa saja sanksi yang dikenakan bagi pihak yang melanggar ketentuan?\\nAnswer:\"\n",
    "completion = complete(user_prompt)\n",
    "print(\"\\n--- Completion ---\")\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c41af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rlaifenv )",
   "language": "python",
   "name": "rlaifenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
