{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b020865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "login(token=\"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\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1f5e7",
   "metadata": {},
   "source": [
    "# **Store Data to HF Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80acd969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f97870d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your split files\n",
    "DATA = {\n",
    "    \"train\": \"../datasets_full_training_and_test/cqa_full_training_prompt_completion.jsonl\",\n",
    "    \"test\":  \"../datasets_full_training_and_test/cqa_test_prompt_completion.jsonl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef8c3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a DatasetDict\n",
    "raw = DatasetDict({\n",
    "    \"train\": load_dataset(\"json\", data_files=DATA[\"train\"], split=\"train\"),\n",
    "    \"test\":  load_dataset(\"json\", data_files=DATA[\"test\"],  split=\"train\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ec45f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the repo you want to create on HF\n",
    "DATASET_REPO = \"xmriz/ojk-qna-regulations-90-10\"\n",
    "\n",
    "# Push to Hub (public; set private=True if needed)\n",
    "raw.push_to_hub(\n",
    "    repo_id=DATASET_REPO,\n",
    "    private=False,\n",
    "    token=os.environ.get(\"HF_TOKEN\")  # login() has already saved your token\n",
    ")\n",
    "print(f\"✅ Dataset available at https://huggingface.co/{DATASET_REPO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9d7b6",
   "metadata": {},
   "source": [
    "# **Store Model to HF Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9abc7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6eaaa5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME   = \"xmriz\"\n",
    "MODEL_KEYS = [\"Meta-Llama-3.1-8B\",\"Aya-23-8B\",\"SeaLLMs-v3-7B\",\"SEA-LION-v3-8B\",\"Sahabat-AI-8B\"]\n",
    "WORKFLOWS  = [\"sft20\",\"sft45\",\"sft_only\",\"dpo45\",\"dpo70\",\"dpo_only\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71acd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "TA_ROOT = Path.cwd().parent\n",
    "\n",
    "def adapter_folder(wf, key):\n",
    "    \"\"\"Return the adapter-only folder (containing LoRA weights)\"\"\"\n",
    "    prefix = \"sft_output\" if wf.startswith(\"sft\") else \"dpo_output\"\n",
    "    return TA_ROOT / wf / f\"{prefix}_{key}\" / \"final_checkpoint\"\n",
    "\n",
    "def base_cache_folder(key):\n",
    "    \"\"\"Where your base model/tokenizer are cached locally\"\"\"\n",
    "    return TA_ROOT / \"model_cache\" / key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fbec2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "➡️  Preparing to push xmriz/sft20_Meta-Llama-3.1-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft20/sft_output_Meta-Llama-3.1-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Meta-Llama-3.1-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.37s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:03<00:00, 4.30MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:01<00:00, 11.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft20_Meta-Llama-3.1-8B: https://huggingface.co/xmriz/sft20_Meta-Llama-3.1-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft20_Aya-23-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft20/sft_output_Aya-23-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Aya-23-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:01<00:00, 13.5MB/s]\n",
      "tokenizer.json: 100%|██████████| 20.1M/20.1M [00:01<00:00, 12.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft20_Aya-23-8B: https://huggingface.co/xmriz/sft20_Aya-23-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft20_SeaLLMs-v3-7B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft20/sft_output_SeaLLMs-v3-7B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SeaLLMs-v3-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.05it/s]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 10.1M/10.1M [00:01<00:00, 9.41MB/s]\n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:01<00:00, 8.53MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft20_SeaLLMs-v3-7B: https://huggingface.co/xmriz/sft20_SeaLLMs-v3-7B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft20_SEA-LION-v3-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft20/sft_output_SEA-LION-v3-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SEA-LION-v3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.36s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:01<00:00, 7.12MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:03<00:00, 5.24MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft20_SEA-LION-v3-8B: https://huggingface.co/xmriz/sft20_SEA-LION-v3-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft20_Sahabat-AI-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft20/sft_output_Sahabat-AI-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Sahabat-AI-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.39s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:02<00:00, 4.93MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:03<00:00, 4.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft20_Sahabat-AI-8B: https://huggingface.co/xmriz/sft20_Sahabat-AI-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft45_Meta-Llama-3.1-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft45/sft_output_Meta-Llama-3.1-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Meta-Llama-3.1-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.42s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 2.96MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:04<00:00, 3.68MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft45_Meta-Llama-3.1-8B: https://huggingface.co/xmriz/sft45_Meta-Llama-3.1-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft45_Aya-23-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft45/sft_output_Aya-23-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Aya-23-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.34s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:05<00:00, 2.62MB/s]\n",
      "tokenizer.json: 100%|██████████| 20.1M/20.1M [00:06<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft45_Aya-23-8B: https://huggingface.co/xmriz/sft45_Aya-23-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft45_SeaLLMs-v3-7B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft45/sft_output_SeaLLMs-v3-7B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SeaLLMs-v3-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 10.1M/10.1M [00:02<00:00, 3.47MB/s]\n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:03<00:00, 3.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft45_SeaLLMs-v3-7B: https://huggingface.co/xmriz/sft45_SeaLLMs-v3-7B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft45_SEA-LION-v3-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft45/sft_output_SEA-LION-v3-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SEA-LION-v3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 3.32MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:04<00:00, 3.81MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft45_SEA-LION-v3-8B: https://huggingface.co/xmriz/sft45_SEA-LION-v3-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft45_Sahabat-AI-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft45/sft_output_Sahabat-AI-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Sahabat-AI-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.41s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:03<00:00, 3.92MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:05<00:00, 3.16MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft45_Sahabat-AI-8B: https://huggingface.co/xmriz/sft45_Sahabat-AI-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft_only_Meta-Llama-3.1-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft_only/sft_output_Meta-Llama-3.1-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Meta-Llama-3.1-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 2.85MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:05<00:00, 3.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft_only_Meta-Llama-3.1-8B: https://huggingface.co/xmriz/sft_only_Meta-Llama-3.1-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft_only_Aya-23-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft_only/sft_output_Aya-23-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Aya-23-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.14s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:03<00:00, 3.72MB/s]\n",
      "tokenizer.json: 100%|██████████| 20.1M/20.1M [00:06<00:00, 2.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft_only_Aya-23-8B: https://huggingface.co/xmriz/sft_only_Aya-23-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft_only_SeaLLMs-v3-7B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft_only/sft_output_SeaLLMs-v3-7B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SeaLLMs-v3-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 10.1M/10.1M [00:02<00:00, 3.63MB/s]\n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:04<00:00, 2.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft_only_SeaLLMs-v3-7B: https://huggingface.co/xmriz/sft_only_SeaLLMs-v3-7B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft_only_SEA-LION-v3-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft_only/sft_output_SEA-LION-v3-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SEA-LION-v3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.47s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 3.33MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:06<00:00, 2.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft_only_SEA-LION-v3-8B: https://huggingface.co/xmriz/sft_only_SEA-LION-v3-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/sft_only_Sahabat-AI-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/sft_only/sft_output_Sahabat-AI-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Sahabat-AI-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.44s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 3.09MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:04<00:00, 3.90MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/sft_only_Sahabat-AI-8B: https://huggingface.co/xmriz/sft_only_Sahabat-AI-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo45_Meta-Llama-3.1-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo45/dpo_output_Meta-Llama-3.1-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Meta-Llama-3.1-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.58s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:03<00:00, 3.70MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:04<00:00, 3.84MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo45_Meta-Llama-3.1-8B: https://huggingface.co/xmriz/dpo45_Meta-Llama-3.1-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo45_Aya-23-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo45/dpo_output_Aya-23-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Aya-23-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.42s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 2.78MB/s]\n",
      "tokenizer.json: 100%|██████████| 20.1M/20.1M [00:07<00:00, 2.80MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo45_Aya-23-8B: https://huggingface.co/xmriz/dpo45_Aya-23-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo45_SeaLLMs-v3-7B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo45/dpo_output_SeaLLMs-v3-7B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SeaLLMs-v3-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:00<00:00, 16.01it/s]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 10.1M/10.1M [00:03<00:00, 3.23MB/s]\n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:03<00:00, 3.37MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo45_SeaLLMs-v3-7B: https://huggingface.co/xmriz/dpo45_SeaLLMs-v3-7B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo45_SEA-LION-v3-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo45/dpo_output_SEA-LION-v3-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SEA-LION-v3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:05<00:00, 2.64MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:04<00:00, 3.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo45_SEA-LION-v3-8B: https://huggingface.co/xmriz/dpo45_SEA-LION-v3-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo45_Sahabat-AI-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo45/dpo_output_Sahabat-AI-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Sahabat-AI-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.41s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:03<00:00, 3.63MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:07<00:00, 2.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo45_Sahabat-AI-8B: https://huggingface.co/xmriz/dpo45_Sahabat-AI-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo70_Meta-Llama-3.1-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo70/dpo_output_Meta-Llama-3.1-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Meta-Llama-3.1-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.42s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 2.76MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:06<00:00, 2.70MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo70_Meta-Llama-3.1-8B: https://huggingface.co/xmriz/dpo70_Meta-Llama-3.1-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo70_Aya-23-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo70/dpo_output_Aya-23-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Aya-23-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 2.86MB/s]\n",
      "tokenizer.json: 100%|██████████| 20.1M/20.1M [00:05<00:00, 3.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo70_Aya-23-8B: https://huggingface.co/xmriz/dpo70_Aya-23-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo70_SeaLLMs-v3-7B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo70/dpo_output_SeaLLMs-v3-7B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SeaLLMs-v3-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 10.1M/10.1M [00:04<00:00, 2.10MB/s]\n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:03<00:00, 2.88MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo70_SeaLLMs-v3-7B: https://huggingface.co/xmriz/dpo70_SeaLLMs-v3-7B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo70_SEA-LION-v3-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo70/dpo_output_SEA-LION-v3-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SEA-LION-v3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.43s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 3.09MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:06<00:00, 2.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo70_SEA-LION-v3-8B: https://huggingface.co/xmriz/dpo70_SEA-LION-v3-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo70_Sahabat-AI-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo70/dpo_output_Sahabat-AI-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Sahabat-AI-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.41s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:04<00:00, 3.03MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:07<00:00, 2.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo70_Sahabat-AI-8B: https://huggingface.co/xmriz/dpo70_Sahabat-AI-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo_only_Meta-Llama-3.1-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo_only/dpo_output_Meta-Llama-3.1-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Meta-Llama-3.1-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:05<00:00, 2.47MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:05<00:00, 3.42MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo_only_Meta-Llama-3.1-8B: https://huggingface.co/xmriz/dpo_only_Meta-Llama-3.1-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo_only_Aya-23-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo_only/dpo_output_Aya-23-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Aya-23-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:05<00:00, 2.63MB/s]\n",
      "tokenizer.json: 100%|██████████| 20.1M/20.1M [00:04<00:00, 4.15MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo_only_Aya-23-8B: https://huggingface.co/xmriz/dpo_only_Aya-23-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo_only_SeaLLMs-v3-7B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo_only/dpo_output_SeaLLMs-v3-7B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SeaLLMs-v3-7B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 10.1M/10.1M [00:04<00:00, 2.30MB/s]\n",
      "tokenizer.json: 100%|██████████| 11.4M/11.4M [00:04<00:00, 2.74MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo_only_SeaLLMs-v3-7B: https://huggingface.co/xmriz/dpo_only_SeaLLMs-v3-7B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo_only_SEA-LION-v3-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo_only/dpo_output_SEA-LION-v3-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/SEA-LION-v3-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:06<00:00, 2.20MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:07<00:00, 2.39MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo_only_SEA-LION-v3-8B: https://huggingface.co/xmriz/dpo_only_SEA-LION-v3-8B\n",
      "\n",
      "➡️  Preparing to push xmriz/dpo_only_Sahabat-AI-8B\n",
      "    • Adapter dir:   /raid/home/llmsosmed/test-amriz/TA/dpo_only/dpo_output_Sahabat-AI-8B/final_checkpoint\n",
      "    • Tokenizer dir: /raid/home/llmsosmed/test-amriz/TA/model_cache/Sahabat-AI-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n",
      "/raid/home/llmsosmed/ta-rl-new-env/lib/python3.10/site-packages/transformers/utils/hub.py:920: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 13.6M/13.6M [00:05<00:00, 2.55MB/s]\n",
      "tokenizer.json: 100%|██████████| 17.2M/17.2M [00:05<00:00, 3.04MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed xmriz/dpo_only_Sahabat-AI-8B: https://huggingface.co/xmriz/dpo_only_Sahabat-AI-8B\n"
     ]
    }
   ],
   "source": [
    "for wf in WORKFLOWS:\n",
    "    for key in MODEL_KEYS:\n",
    "        repo_id         = f\"{USERNAME}/{wf}_{key}\"\n",
    "        adapter_path    = adapter_folder(wf, key)\n",
    "        tokenizer_cache = base_cache_folder(key)\n",
    "\n",
    "        print(f\"\\n➡️  Preparing to push {repo_id}\")\n",
    "        print(f\"    • Adapter dir:   {adapter_path}\")\n",
    "        print(f\"    • Tokenizer dir: {tokenizer_cache}\")\n",
    "\n",
    "        # 3.1 Load tokenizer from base cache\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            str(tokenizer_cache),\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "        # 3.2 Load base LM, then merge in the adapter\n",
    "        base_model = AutoModelForCausalLM.from_pretrained(\n",
    "            str(tokenizer_cache),\n",
    "            device_map=\"auto\",\n",
    "            local_files_only=True\n",
    "        )\n",
    "        peft_model = PeftModel.from_pretrained(\n",
    "            base_model,\n",
    "            str(adapter_path),\n",
    "            device_map=\"auto\",\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "        # 3.3 Push merged model + tokenizer\n",
    "        peft_model.push_to_hub(repo_id, use_auth_token=True)\n",
    "        tokenizer.push_to_hub(repo_id, use_auth_token=True)\n",
    "\n",
    "        print(f\"✅ Pushed {repo_id}: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f56db073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_collection, add_collection_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6a229aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔗 Collection created: xmriz/tugas-akhir-684a951a5847126885eea03f\n"
     ]
    }
   ],
   "source": [
    "collection = create_collection(\n",
    "    title=\"Tugas Akhir\",\n",
    "    description=\"Koleksi semua model SFT & DPO hasil Tugas Akhir pada dataset QA OJK\",\n",
    "    private=False\n",
    ")\n",
    "slug = collection.slug\n",
    "print(f\"\\n🔗 Collection created: {slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fda263cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Added to collection: xmriz/sft20_Meta-Llama-3.1-8B\n",
      "✅ Added to collection: xmriz/sft20_Aya-23-8B\n",
      "✅ Added to collection: xmriz/sft20_SeaLLMs-v3-7B\n",
      "✅ Added to collection: xmriz/sft20_SEA-LION-v3-8B\n",
      "✅ Added to collection: xmriz/sft20_Sahabat-AI-8B\n",
      "✅ Added to collection: xmriz/sft45_Meta-Llama-3.1-8B\n",
      "✅ Added to collection: xmriz/sft45_Aya-23-8B\n",
      "✅ Added to collection: xmriz/sft45_SeaLLMs-v3-7B\n",
      "✅ Added to collection: xmriz/sft45_SEA-LION-v3-8B\n",
      "✅ Added to collection: xmriz/sft45_Sahabat-AI-8B\n",
      "✅ Added to collection: xmriz/sft_only_Meta-Llama-3.1-8B\n",
      "✅ Added to collection: xmriz/sft_only_Aya-23-8B\n",
      "✅ Added to collection: xmriz/sft_only_SeaLLMs-v3-7B\n",
      "✅ Added to collection: xmriz/sft_only_SEA-LION-v3-8B\n",
      "✅ Added to collection: xmriz/sft_only_Sahabat-AI-8B\n",
      "✅ Added to collection: xmriz/dpo45_Meta-Llama-3.1-8B\n",
      "✅ Added to collection: xmriz/dpo45_Aya-23-8B\n",
      "✅ Added to collection: xmriz/dpo45_SeaLLMs-v3-7B\n",
      "✅ Added to collection: xmriz/dpo45_SEA-LION-v3-8B\n",
      "✅ Added to collection: xmriz/dpo45_Sahabat-AI-8B\n",
      "✅ Added to collection: xmriz/dpo70_Meta-Llama-3.1-8B\n",
      "✅ Added to collection: xmriz/dpo70_Aya-23-8B\n",
      "✅ Added to collection: xmriz/dpo70_SeaLLMs-v3-7B\n",
      "✅ Added to collection: xmriz/dpo70_SEA-LION-v3-8B\n",
      "✅ Added to collection: xmriz/dpo70_Sahabat-AI-8B\n",
      "✅ Added to collection: xmriz/dpo_only_Meta-Llama-3.1-8B\n",
      "✅ Added to collection: xmriz/dpo_only_Aya-23-8B\n",
      "✅ Added to collection: xmriz/dpo_only_SeaLLMs-v3-7B\n",
      "✅ Added to collection: xmriz/dpo_only_SEA-LION-v3-8B\n",
      "✅ Added to collection: xmriz/dpo_only_Sahabat-AI-8B\n",
      "\n",
      "🎉 All done! Your models are grouped under the 'Tugas Akhir' collection.\n"
     ]
    }
   ],
   "source": [
    "for wf in WORKFLOWS:\n",
    "    for key in MODEL_KEYS:\n",
    "        repo_id = f\"{USERNAME}/{wf}_{key}\"\n",
    "        add_collection_item(\n",
    "            collection_slug=slug,\n",
    "            item_id=repo_id,\n",
    "            item_type=\"model\",\n",
    "            exists_ok=True\n",
    "        )\n",
    "        print(f\"✅ Added to collection: {repo_id}\")\n",
    "\n",
    "print(\"\\n🎉 All done! Your models are grouped under the 'Tugas Akhir' collection.\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta-rl-new-env",
   "language": "python",
   "name": "ta-rl-new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
