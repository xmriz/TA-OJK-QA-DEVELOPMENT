{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2543afaa",
   "metadata": {},
   "source": [
    "# **Download Model from HF Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58fa4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from huggingface_hub import snapshot_download\n",
    "from huggingface_hub.utils import RepositoryNotFoundError, LocalEntryNotFoundError\n",
    "from requests.exceptions import ReadTimeout, ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1a4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_snapshot_until_success(\n",
    "    repo_id: str,\n",
    "    cache_dir: str,\n",
    "    local_dir: str,\n",
    "    use_auth_token: str = None,\n",
    "    backoff_factor: float = 2.0,\n",
    "    initial_delay: float = 5.0,\n",
    "    max_delay: float = 300.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Continuously retry downloading the full snapshot of a Hugging Face model\n",
    "    until it succeeds. On transient errors (timeouts, connection issues,\n",
    "    missing local entries), it will back off exponentially but never give up.\n",
    "    \"\"\"\n",
    "    delay = initial_delay\n",
    "    while True:\n",
    "        try:\n",
    "            path = snapshot_download(\n",
    "                repo_id=repo_id,\n",
    "                cache_dir=cache_dir,\n",
    "                local_dir=local_dir,\n",
    "                use_auth_token=use_auth_token,\n",
    "                local_dir_use_symlinks=False\n",
    "            )\n",
    "            print(f\"✓ Successfully downloaded {repo_id} to {local_dir}\")\n",
    "            return path\n",
    "        except RepositoryNotFoundError:\n",
    "            # Fatal: repo doesn't exist or you lack access\n",
    "            print(f\"❌ Repository not found or access denied: {repo_id}\")\n",
    "            raise\n",
    "        except (ReadTimeout, ConnectionError, LocalEntryNotFoundError) as e:\n",
    "            print(f\"⚠️  Download error for {repo_id}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Unexpected error for {repo_id}: {e}\")\n",
    "\n",
    "        # back off and retry\n",
    "        print(f\"→ Retrying in {delay:.1f}s …\")\n",
    "        time.sleep(delay)\n",
    "        delay = min(delay * backoff_factor, max_delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1365cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "model_names = {\n",
    "    \"Meta-Llama-3.1-8B\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    \"Aya-23-8B\":         \"CohereLabs/aya-23-8B\",\n",
    "    \"SeaLLMs-v3-7B\":     \"SeaLLMs/SeaLLMs-v3-7B\",\n",
    "    \"SEA-LION-v3-8B\":    \"aisingapore/Llama-SEA-LION-v3-8B-IT\",\n",
    "    \"Sahabat-AI-8B\":     \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\"\n",
    "}\n",
    "hf_token = \"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\"\n",
    "cache_dir = \"../model_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3fad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "↓ Downloading snapshot for Meta-Llama-3.1-8B (meta-llama/Llama-3.1-8B-Instruct) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 17 files: 100%|██████████| 17/17 [05:54<00:00, 20.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully downloaded meta-llama/Llama-3.1-8B-Instruct to ../model_cache/Meta-Llama-3.1-8B\n",
      "\n",
      "↓ Downloading snapshot for Aya-23-8B (CohereLabs/aya-23-8B) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 14 files: 100%|██████████| 14/14 [02:32<00:00, 10.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully downloaded CohereLabs/aya-23-8B to ../model_cache/Aya-23-8B\n",
      "\n",
      "↓ Downloading snapshot for SeaLLMs-v3-7B (SeaLLMs/SeaLLMs-v3-7B) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 19 files: 100%|██████████| 19/19 [04:30<00:00, 14.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully downloaded SeaLLMs/SeaLLMs-v3-7B to ../model_cache/SeaLLMs-v3-7B\n",
      "\n",
      "↓ Downloading snapshot for SEA-LION-v3-8B (aisingapore/Llama-SEA-LION-v3-8B-IT) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 14 files: 100%|██████████| 14/14 [02:23<00:00, 10.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully downloaded aisingapore/Llama-SEA-LION-v3-8B-IT to ../model_cache/SEA-LION-v3-8B\n",
      "\n",
      "↓ Downloading snapshot for Sahabat-AI-8B (GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct) …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 12 files: 100%|██████████| 12/12 [02:20<00:00, 11.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully downloaded GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct to ../model_cache/Sahabat-AI-8B\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model_key, repo_id in model_names.items():\n",
    "    print(f\"↓ Downloading snapshot for {model_key} ({repo_id}) …\")\n",
    "    download_snapshot_until_success(\n",
    "        repo_id=repo_id,\n",
    "        cache_dir=cache_dir,\n",
    "        local_dir=f\"{cache_dir}/{model_key}\",\n",
    "        use_auth_token=hf_token\n",
    "    )\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta-rl-new-env",
   "language": "python",
   "name": "ta-rl-new-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
